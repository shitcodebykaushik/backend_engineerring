# The backend from the engineering pov:_
Backend enginerring is form of art.
It all about the communication of backend .
Everything work under the one wire.
Performance latency and debug,bug everything works on the concept of connecting wires.
How the connection is established?
How these kernal choose the backend application?
WITHOUT KNOWING HOW Application how system work is horrible way of learning.
Never rely on orderning when it comes to backend that's why pipekine has been discontinued.

# Rewquest - Response
This is first communication design pattern for the communication

- Client sends a Request
  First of all client need to define what the request is and backend  need to understand it properly, this is continosly stream of a data. And the server need to look for the start of the data and end of the data.


- Server parses the Request 
  Server relly need to understand that where the request begin and where the request end .
  The cost of parsing the request is not a cheap .

- Server process the Request

- Server sends a response

- Client parses the Response and consume 

 # Where Request and Response  is used ?
  - Web,HTTP,DNS,SSH
  - RPC (remote procedure call)  
  - SQL and Database protocols 
  - API (REST/SOAP/GraphQL)
   Note in `REST` everything we define is request.

# Anatomy of Request/Response
 - A request structure is defined by the both client and server.
 - Request has a boundry 
 - Defined by a protocol and a message format



# Building an upload image with the request response

- 1. Send large request with the image (simple).
   - Each time server have to say ok ()

 - 2. Chunk image and send a rw=wquest per chunk (resumable). 
    - Once the connection is lost then also client can come back and say to the server hey lets do it agian.


Doesn't work evrywhere
 - Notification serveice (In this the backed have the knowledge but client doesn't)
 - Chatting application .
 - Very long request.
 - What if client disconnets.

# Synchronous Vs Asynchronous
 - In simple can i do work while waiting?
  Sync means they are goin in same way.
  Async means they are not going in same way. We should always prefer this as i want client to do something different and server to do something completely different.


- Synchronous I/O
   - Caller sends a request and blocks which means that one proceess need to finished first then only we go for next,it will block every line of code once the process has been implemented.Caller cannot execute any code meanwhile .

   - Receiver responds and caller will be unblocks 
   - Caller and receiver are in sync.
   - Synchronicity is a client property.
   - Asking question in meeeting where wait for the reply
- Asynchronous I/O
   - Sendinf email is best example where we ssent the mail once and works on different things.
  - Caller sends a request 
  - Caller can work until it gets a response.
  - Modern client libraries are async
  - Caller either :
     - Checks if the response is ready (epoll)
     - Receiver calls backs when its's done (io_uring)
     - Spins up a new thread that blocks 
  - Caller and reciever are not necessary in sync.
    Note try to implement the simple code in rust 

# Push 
This is another design pattern for comminication
 - Clients wants a real time notification from backend .In these case request/response doent fit well

   -  A user logged in 
   -  A meesage is just received
- A push model is good for certain case 
   - Clients connect server to a server
   - Servers sends data to the client
   - Clinet doesn't have to request anything 
   - Protocol must be biderectional
   - Used by RabbitMQ
   - Realtime as things happens the client will known the stuff 
   - Client must be online means that it should be physically connected to the server 
   - Client might not be able to handle as we pushinf the data to the client withouth carrying what client will do .
   - Polling is prefered  for the light client .
  
 - It is a bidirectional connection. And it requires the bidirectional protocol.

    

# Short Polling 
 The idea of polling is to make request and response.
  This is next paart of design pattern .
- When request/response isn't ideal
 - A request takes long time to process
   - Upload a youtube video
 - The backend wants to send a notification 
    - A user just logged in.
 - Polling is good communication method
 What is Short Polling.
 - Client sends a request
 - Server responds immediately with the handle
 - Server continues to process the request
 - Client uses that handle to check for status. Until the response was complited then only we respond.
 - Multiple "short" request response as polls.
 -Pros
  - Simple
  - Good for long running requests
  - Client can discconect
- Cons
  - Too chatty
  - Network bandwidth 
  - Wasted Backend resouces

# Long polling  
Where request/response & polling isnt ideal
 Kafka using this .
  Request is taking long, I will check with you later,But talk to me only when its ready.
  - Client sends a request .
  - Server responds immediately with a handle
  - Server continues to process the request 
  - Client uses that handle to check for status 
  - Server  DOES not reply until it has the response
  - So WE got a handle,we can disconnected
  - Some variation has timeouts too.
  - The way it works is totaly dofferent from short polling .
    Suppose a client sends a request then the server will send the request the id to the client ,as soon as the the client will ask to the server that is ID x is ready then server will not response to the client until the rewest is ready.
  - Pros
   - Less chatty and backend friendly
   - Client can still disconnect 
  - Cons
    - Not real time 

  # Server Sent Events 
  One request a very very long response 
  This is pure http model.
   - A response has start and end
   - Client sends a request
   - Server sends a logical events as part of response
   - Server never writes the end of the response
   - It is still a request but an unending response
   - Client parse the streams data looking for this events 
   - Works with the request/response (HTTP).
  -  Pros
     - Real time 
     - Compatible with the request/response
  - Cons 
     - Clients must be online
     - Clients might not be able to handle
     - Polling is preferred for light clients
     - HTTP/1.1 problem (6 connection)
  # Publish Subscribe 
   One publisher many readers      

   - Pros
    Scales w/ mutltiple recievers
    Great for microservice
    Loose Coupling
    Works while clients not running
  - Cons
    Message delivery issue (Two generals problems)
     Complexity
     Network  Saturation

  # Multiplexing vs Demultiplexing 
   HTTP/2,QUICE, Connection Pool ,MPTCP

   - Taking multiple connection and sending them into one. This is multiplexing reverse of this  will be demultiplexing.
   In mux More throughtput High backend resources (CPU for h2) .
    In demux we have less throughput low backend resources (simple h1 ) .

    -  Connection Pooling 
     In this we can spin up multiple connection and we can keep them hot .
     The order is not gurantee .
     In pipleing we have multi query support where we can support the multiple quert at once.
     Chrome allow up to 6 connection per domain , users rewuest are demultiplexed ,
     
  # Stateless and Stateful backend
   Is state stored  in the backend ?
   It is the style of the storing application in the backend .

 - Stateful
   Stores state about clients in its memorry
   Depends on the information being there

 - Stateless
   - Client is responsible to transfer the state with the every request
   - May store but can safely loose it 
   - Stateless backend can still store data somewhere else
   - Can you restart the backend during idle time while the client workflow continues to work.
   - The backend remian stateless but the system is stateful
   - Stateful vs Stateless protocol

    - The Protocols can be designed to store state
    - TCP is stateful
     - Sequence,Connection file descriptor
    - UDP is stateless
     - DNS send queryID in UDP to identify queries
     - QUIC send conncetionID to identify connection. [It is statefull in most of case but UDP is statelss]

    -  You can build a stateless prtocol on top of a statefull one and vise versa
    - HTTP on top of TCP 
    - If TCP breaks,HTTP blindly create another one
    - QUIC on top UDP 

  - Complete Stateless System
   - Stateless system are rare
   - State is carried with every request
   - A backend that relies completely on the input 
     - Check if input param is a prime number 
   - JWT (JSON Web Token)

  - Sidecar Pattern 
   Thick clients,Thicker backends .
   You have to know how to write the socket in a particular language , and you have to read all the complex.
   - Every prtocols require a library .
    - You need to use the library to built the particulare software .
    - `CURL` is client library as it know to talk to the client .
    - You can use the TLS LIBRARY (open ssl) and then to decrypt the data at server side  we can use the TLS(rUstSSL) .
    - grpc client grpc library the to decrpyt also we are using the same library .
    - Changing the library is hard .
    - Once you use the library your app is entrenched .
    - App & Library should be the same language 
    - Changing the library require retesting .
    - Breaking changes backward compatibilty
    - Adding fetaures to the library is hard .
    - Microservice suffer .

     // Use of proxy is left /

# Protcols
Motivation you can come through your own protocol .

At the end of the performance matters,these are the sub of the protocol .
- A system that allows the two parties to communicate .
- A protocol is desgned with the set of properties .
- Depending on the purpose of the protocol.
- TCP,UDP,HTTP,gRPC,FTP .
Properties of the protocol are :-
 - Data format .
   - Text based (paline text ,JSON,XML).
   - Binary (protobuf,RESP,H2,h3)
 - Trnasfer Mode
   - Message based (UDP,HTTP)
   - Stream (TCP,WebRTC).
 - Addressing system 
    - DNS name,IP,MAC   
 - Directional
  - Bidirectional (TCP)
  - Unidirection (HTTP)
  - Full /Half duplex
- Sate 
 - Stateful (TCP,gRPC,apache thrift)
 - Staless (UDP,HTTP)
- Routing 
  - Proxies, GateWays
- Flow & Congestion control .
- Error management 


  
# MiddleWare 
Middleware are the function that have acces to the requwest object ,the response object and the next middleware function in the application request-response cycle .The next middleware is commonly denoted by the name of the next  .
- Error handling middle-ware will takes the four argunments .
- Middleware can be declared as the array for the resualbility .
- Route hqandler helps you to define the multple routes path .
-   

# Routing 
- It refers to the how an application endpoints will responds to the cliet .
 ```js
 app.Methods(Path,Handler)
 ```
 - app is the instance of the express .
 - Method is the HTTP request mathod .
 - Path is the path on the server .
 - Handler are the function executed when the route are the matched .


# Headers
       



